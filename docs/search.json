[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I am a current junior at St. Olaf College studying Psychology and International Relations. After I graduate from St. Olaf, I hope to go to graduate school to pursue a degree in Industrial-Organizational Psychology. Outside of class, I am a figure skater in the St. Olaf figure skating club and a member of the Norseman Band. In my free time, I enjoy reading, baking, traveling, hiking, and spending time outside!\n\n\n\nI traveled to Norway this past summer!"
  },
  {
    "objectID": "about.html#about-me",
    "href": "about.html#about-me",
    "title": "About",
    "section": "",
    "text": "I am a current junior at St. Olaf College studying Psychology and International Relations. After I graduate from St. Olaf, I hope to go to graduate school to pursue a degree in Industrial-Organizational Psychology. Outside of class, I am a figure skater in the St. Olaf figure skating club and a member of the Norseman Band. In my free time, I enjoy reading, baking, traveling, hiking, and spending time outside!\n\n\n\nI traveled to Norway this past summer!"
  },
  {
    "objectID": "mini_project4.html",
    "href": "mini_project4.html",
    "title": "NYTimes Text Analysis",
    "section": "",
    "text": "I’ve always had an interest in current events, and growing up, I read the newspaper every morning. As an International Relations concentrator, I continue to be interested in events occurring around the world. I decided to work with the New York Times dataset for this project because I am interested how different international events and countries have been portrayed in the media in the past, and how the overall sentiment toward these countries and events has changed. I hope to explore how certain events, both domestically and internationally, have changed the sentiment or number of articles written on certain topics. The data for this project comes from the NYTimes dataset included in the RTextTools package. The dataset consists of the headlines of front-page NYTimes articles from 1996 to 2006."
  },
  {
    "objectID": "mini_project4.html#introduction",
    "href": "mini_project4.html#introduction",
    "title": "NYTimes Text Analysis",
    "section": "",
    "text": "I’ve always had an interest in current events, and growing up, I read the newspaper every morning. As an International Relations concentrator, I continue to be interested in events occurring around the world. I decided to work with the New York Times dataset for this project because I am interested how different international events and countries have been portrayed in the media in the past, and how the overall sentiment toward these countries and events has changed. I hope to explore how certain events, both domestically and internationally, have changed the sentiment or number of articles written on certain topics. The data for this project comes from the NYTimes dataset included in the RTextTools package. The dataset consists of the headlines of front-page NYTimes articles from 1996 to 2006."
  },
  {
    "objectID": "mini_project4.html#common-words-and-sentiments-in-nytimes-articles",
    "href": "mini_project4.html#common-words-and-sentiments-in-nytimes-articles",
    "title": "NYTimes Text Analysis",
    "section": "Common Words and Sentiments in NYTimes Articles",
    "text": "Common Words and Sentiments in NYTimes Articles\nTo begin my analysis, I started by making a wordcloud of the New York Times articles to see which topics continually reappeared in the headlines."
  },
  {
    "objectID": "mini_project4.html#wordcloud",
    "href": "mini_project4.html#wordcloud",
    "title": "NYTimes Text Analysis",
    "section": "WordCloud",
    "text": "WordCloud\n\n#tidying data \ntidy_times &lt;- nytimes |&gt;\n  mutate(Subject = as.character(Subject),\n         Date = as.character(Date),\n         Title = as.character(Title)) |&gt;\n  unnest_tokens(word, Title, token = \"words\")\n\n#creating data for wordcloud\ntimes_wordcloud &lt;- tidy_times |&gt;\n  anti_join(stop_words) |&gt;\n  count(word) |&gt;\n  filter(!str_detect(word, \"\\\\d\")) |&gt;\n  arrange(desc(n)) |&gt;\n  slice_head(n = 80)\n\nJoining with `by = join_by(word)`\n\n#wordcloud\n  wordcloud2(\n  times_wordcloud, \n  size = 1, \n  shape = 'circle',\n  minSize = 3,\n  color = 'random-dark'\n)\n\n\n\n\n\nBased on this wordcloud, common topics that frequently appear in the headlines concern domestic politics, the economy, elections, and international conflicts and relations. Oftentimes, the context of these headlines are negative. When examining the overall sentiment of articles for every week from 1996 to 2006, the sentiment is overwhelming negative, with very few weeks across both decades displaying an overall positive sentiment."
  },
  {
    "objectID": "mini_project4.html#overall-article-sentiment-by-week",
    "href": "mini_project4.html#overall-article-sentiment-by-week",
    "title": "NYTimes Text Analysis",
    "section": "Overall Article Sentiment By Week",
    "text": "Overall Article Sentiment By Week\n\n#loading sentiment data\nbing_sentiments &lt;- get_sentiments(lexicon = \"bing\")\n\n#creating article by sentiment plot\ntidy_times |&gt;\n  mutate(linenumber = row_number(),\n         decade = ifelse(str_detect(Date, \"^1.*\"), \"1990s\", \"2000s\")) |&gt;\n  inner_join(bing_sentiments) |&gt;\n  count(decade, index = linenumber %/% 70, sentiment) |&gt;\n  pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) |&gt;\n  mutate(sentiment = positive - negative) |&gt;\n  ggplot(aes(x = index, y = sentiment, fill = decade)) +\n    geom_col(show.legend = FALSE) +\n    facet_wrap(~decade, ncol = 2, scales = \"free_x\") +\n    theme_bw() +\n    scale_fill_manual(values = c(\"1990s\" = \"#0047AB\", \"2000s\" = \"maroon\")) +\n    labs(\n      title = \"Overall Sentiment of NY Times Articles by Week\",\n      x = \"Week\",\n      y = \"Sentiment\"\n    )\n\nJoining with `by = join_by(word)`\n\n\n\n\n\n\n\n\n\nConsidering my interest in International Relations, I decided to examine the prevalence of different countries in the news across time. For this analysis, I chose to focus on China, Iraq, and Russia, which are countries that are commonly discussed in International Relations and have been important to foreign affairs in recent decades."
  },
  {
    "objectID": "mini_project4.html#prevalence-of-different-ir-subjects-across-time",
    "href": "mini_project4.html#prevalence-of-different-ir-subjects-across-time",
    "title": "NYTimes Text Analysis",
    "section": "Prevalence of different IR subjects across time",
    "text": "Prevalence of different IR subjects across time\n\n#creating count of different subjects plot\nnytimes |&gt;\n  mutate(Subject = str_to_lower(Subject),\n         year = str_extract(as.character(Date), \"\\\\d{2}$\"),\n         century = ifelse(str_detect(year, \"^9.\"), \"19\", \"20\"),\n         year = as.integer(str_c(century, year))) |&gt;\n  filter(str_detect(Subject, \"(russia|china|iraq)\")) |&gt;\n  mutate(ir_subject = str_extract(Subject, \"(russia|china|iraq)\"),\n         ir_subject = str_to_title(ir_subject)) |&gt;\n  group_by(year, ir_subject) |&gt;\n  summarize(n = n(), .groups = \"drop\") |&gt;\n  ggplot(aes(x = year, y = n, fill = ir_subject)) +\n    geom_col(position = \"dodge\", color = \"black\") +\n    scale_y_continuous(breaks = pretty_breaks(n = 4)) +\n    scale_fill_manual(values = c(\"China\" = \"maroon\", \"Iraq\" = \"gold\", \"Russia\" = \"#0047AB\")) +\n    labs(\n      title = \"Number of Occurences of International Relations Topics in NYTimes Articles\",\n      subtitle = \"From 1996 to 2006\",\n      x = \"Year\",\n      y = \"Number of Appearances\",\n      fill = \"IR Subject\"\n    )\n\n\n\n\n\n\n\n\nBased on this visualization, the majority of stories have been written about Iraq during this time period, with a large spike in 2002 and 2003, correlating with the beginning of the Iraq war. More stories were written about Russia and China in the late 19990s compared to Iraq, but the number of these stories tapered off with the start of the Iraq war. Expanding the number of states examined to also include Afghanistan, the Balkans, and the U.S., I wanted to look into the words most correlated with these countries in order to learn what topics were commonly written about when these countries were in the news."
  },
  {
    "objectID": "mini_project4.html#correlated-topics-with-ir-subjects",
    "href": "mini_project4.html#correlated-topics-with-ir-subjects",
    "title": "NYTimes Text Analysis",
    "section": "Correlated topics with IR subjects",
    "text": "Correlated topics with IR subjects\n\nnytimes$Title &lt;- as.character(nytimes$Title)\n\n#sectioning rows to article length\ntimes_section_words &lt;- nytimes |&gt;\n  select(Date, Title) |&gt;\n  mutate(section = row_number() %/% 1) |&gt;\n  unnest_tokens(word, Title) |&gt;\n  filter(!word %in% stop_words$word,\n         !is.na(word))\n\n#finding correlations of articles\nword_cors &lt;- times_section_words |&gt;\n  group_by(word) |&gt;\n  filter(n() &gt;= 5) |&gt;\n  pairwise_cor(word, section, sort = TRUE)\n\n#plot of words correlated with different subjects\nword_cors |&gt;\n  filter(item1 %in% c(\"iraq\", \"china\", \"russia\", \"afghanistan\", \"balkans\")) |&gt;\n  group_by(item1) |&gt;\n  slice_max(correlation, n = 6) |&gt;\n  ungroup() |&gt;\n  mutate(item2 = reorder(item2, correlation),\n        item1 = str_to_title(item1)) |&gt;\n  ggplot(aes(item2, correlation)) +\n    geom_bar(stat = \"identity\", fill = \"maroon\", color = \"black\") +\n    facet_wrap(~item1, scales = \"free\") +\n    coord_flip() +\n    labs(title = \"Words Most Commonly Correlated with International Relations Subjects\",\n         x = \"Correlation\",\n         y = \"\"\n         )\n\n\n\n\n\n\n\n\nBased on these correlations, it appears that news stories about China and Russia were more likely to be about economic issues, while those about Afghanistan, Iraq, and the Balkans referred to the conflicts occurring in these countries during this time period. It is particularly interesting that the word “crisis” has such an extremely strong correlation to the Balkans in comparison to all the other words.\nBeyond just the words most correlated with these countries, I was interested in looking at the sentiment of the articles written about these countries."
  },
  {
    "objectID": "mini_project4.html#sentiments-associated-with-different-ir-subjects",
    "href": "mini_project4.html#sentiments-associated-with-different-ir-subjects",
    "title": "NYTimes Text Analysis",
    "section": "Sentiments Associated with Different IR Subjects",
    "text": "Sentiments Associated with Different IR Subjects\n\n#joining times data with bing sentiments\nbing_word_counts &lt;- tidy_times |&gt;\n  inner_join(get_sentiments(\"bing\")) |&gt;\n  group_by(sentiment, Subject) |&gt;\n  count(word, sentiment, sort = TRUE) |&gt;\n  ungroup()\n\nJoining with `by = join_by(word)`\n\n#creating plot of bing sentiments by subject\nbing_word_counts |&gt;\n  filter(str_detect(Subject, \"(russia|china|iraq|israel)\")) |&gt;\n  mutate(ir_subject = str_extract(Subject, \"(russia|china|iraq|israel)\"),\n         ir_subject = str_to_title(ir_subject)) |&gt;\n  group_by(sentiment) |&gt;\n  slice_max(n, n = 10) |&gt;\n  ggplot(aes(x = ir_subject, fill = sentiment)) +\n    geom_bar(position = \"fill\", color = \"black\") +\n    scale_fill_manual(values = c(\"positive\" = \"#0047AB\", negative = \"maroon\")) +\n    labs(title = \"Sentiment of Articles Associated with IR Subjects\",\n         x = \"IR Subject\",\n         y = \"Proportion of Sentiment\",\n         fill = \"Sentiment\")\n\n\n\n\n\n\n\n\nBased on this plot, the sentiment of articles concerning International Relations subjects are generally negative. This is particularly true of Russia and China, in which the proportion of negative articles written about these countries is 1. Surprisingly, Iraq had the most positive sentiment of associated articles, with almost half of all articles having a more positive sentiment."
  },
  {
    "objectID": "mini_project4.html#conclusion",
    "href": "mini_project4.html#conclusion",
    "title": "NYTimes Text Analysis",
    "section": "Conclusion",
    "text": "Conclusion\nOverall, the sentiment of New York Times Articles from 1996 to 2006 is generally quite negative. The articles about International Relations subjects continue this trend, with lots of negative sentiment associated with these articles, particularly articles written about Russia and China. In the future, further analysis of different countries or subjects could be interesting to examine the sentiment of these topics and how they have differed over time. Furthermore, looking into how the number and sentiment of articles written about Russia and China has changed would be fascinating considering the importance these countries hold in International Relations today."
  },
  {
    "objectID": "miniproject2.html",
    "href": "miniproject2.html",
    "title": "Table Scraping Acquisition",
    "section": "",
    "text": "The following data was obtained from the NCAA’s website of the College Men’s Basketball Standings for the 2024-2025 season. The data used in this project was acquired in an ethical and friendly manner. We used the polite package to table scrape in a respectful manner, and we checked before scraping to ensure that the website allows scraping. We did not scrape any personal or confidential information from this site, and we did not overload the server while scraping.\nThe motivation behind this project stems from March Madness currently taking place. However, on a deeper level, we wish to understand the overall and conference differences in play for the NCAA College Men’s Basketball teams. To narrow our search down to have a more specialized look, we narrowed our focus down to the top five conferences that have won the most championships. However, due to the recent change of the PAC-12 being disbanded, with the most championships titles of 15, there are only four conferences present. This ranking of the championship title by conference was provided by ESPN.\nThere are a few questions that must be asked to investigate our main motivation. What is the relationship between conference performance and overall performance? How does conference play affect a team’s overall performance? What factors play into playing the outcome of conference and non-conference games? Is there a way to predict the NCAA championship tournament winner based off of their performances in overall and conference as well as accounting for the factors of past conference champions?\nAfter accounting for the data being collected and tidied, there are several ways we would like to use this table to help begin to answer those questions. To start, we could demonstrate some simple analysis through plots as well as some statistical skills. These skills could include joining with another data set, checking correlations, and p-values. All of these things could help us to make a prediction for a potential March Madness winner based on the data found. These are just a few ways in which evaluating overall and conference performance could influence the conclusions we base off of the insights received."
  },
  {
    "objectID": "miniproject2.html#introduction",
    "href": "miniproject2.html#introduction",
    "title": "Table Scraping Acquisition",
    "section": "",
    "text": "The following data was obtained from the NCAA’s website of the College Men’s Basketball Standings for the 2024-2025 season. The data used in this project was acquired in an ethical and friendly manner. We used the polite package to table scrape in a respectful manner, and we checked before scraping to ensure that the website allows scraping. We did not scrape any personal or confidential information from this site, and we did not overload the server while scraping.\nThe motivation behind this project stems from March Madness currently taking place. However, on a deeper level, we wish to understand the overall and conference differences in play for the NCAA College Men’s Basketball teams. To narrow our search down to have a more specialized look, we narrowed our focus down to the top five conferences that have won the most championships. However, due to the recent change of the PAC-12 being disbanded, with the most championships titles of 15, there are only four conferences present. This ranking of the championship title by conference was provided by ESPN.\nThere are a few questions that must be asked to investigate our main motivation. What is the relationship between conference performance and overall performance? How does conference play affect a team’s overall performance? What factors play into playing the outcome of conference and non-conference games? Is there a way to predict the NCAA championship tournament winner based off of their performances in overall and conference as well as accounting for the factors of past conference champions?\nAfter accounting for the data being collected and tidied, there are several ways we would like to use this table to help begin to answer those questions. To start, we could demonstrate some simple analysis through plots as well as some statistical skills. These skills could include joining with another data set, checking correlations, and p-values. All of these things could help us to make a prediction for a potential March Madness winner based on the data found. These are just a few ways in which evaluating overall and conference performance could influence the conclusions we base off of the insights received."
  },
  {
    "objectID": "miniproject2.html#table-scraping",
    "href": "miniproject2.html#table-scraping",
    "title": "Table Scraping Acquisition",
    "section": "Table Scraping",
    "text": "Table Scraping\n\n#check permission from provided url\nrobotstxt::paths_allowed(\"https://www.ncaa.com/standings/basketball-men/d1\")\n\n[1] TRUE\n\n#begin a session with the url\nsession &lt;- bow(\"https://www.ncaa.com/standings/basketball-men/d1\", force = TRUE)\n\n#scrape the contents and convert\nresult &lt;- scrape(session) |&gt;\n  html_nodes(css = \"table\") |&gt;\n  html_table(header = TRUE, fill = TRUE)\n\nhead(result, n = 1)\n\n[[1]]\n# A tibble: 19 × 17\n   School       Conference Conference Conference Overall Overall Overall Overall\n   &lt;chr&gt;        &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;  \n 1 \"\"           W          L          PCT        W       L       PCT     STREAK \n 2 \"Duke\"       19         1          0.950      35      4       0.897   Lost 1 \n 3 \"Clemson\"    18         2          0.900      27      7       0.794   Lost 2 \n 4 \"Louisville\" 18         2          0.900      27      8       0.771   Lost 2 \n 5 \"SMU\"        13         7          0.650      24      11      0.686   Lost 1 \n 6 \"Wake Fores… 13         7          0.650      21      11      0.656   Lost 1 \n 7 \"North Caro… 13         7          0.650      23      14      0.622   Lost 1 \n 8 \"Stanford\"   11         9          0.550      21      14      0.600   Lost 1 \n 9 \"Georgia Te… 10         10         0.500      17      17      0.500   Lost 2 \n10 \"Pittsburgh\" 8          12         0.400      17      15      0.531   Lost 1 \n11 \"Florida St… 8          12         0.400      17      15      0.531   Lost 1 \n12 \"Virginia\"   8          12         0.400      15      17      0.469   Lost 2 \n13 \"Notre Dame\" 8          12         0.400      15      18      0.455   Lost 1 \n14 \"Virginia T… 8          12         0.400      13      19      0.406   Lost 3 \n15 \"Syracuse\"   7          13         0.350      14      19      0.424   Lost 1 \n16 \"California\" 6          14         0.300      14      19      0.424   Lost 1 \n17 \"NC State\"   5          15         0.250      12      19      0.387   Lost 1 \n18 \"Boston Col… 4          16         0.200      12      19      0.387   Lost 4 \n19 \"Miami (FL)\" 3          17         0.150      7       24      0.226   Won 1  \n# ℹ 9 more variables: Overall &lt;chr&gt;, Overall &lt;chr&gt;, Overall &lt;chr&gt;,\n#   Overall &lt;chr&gt;, Overall &lt;chr&gt;, Overall &lt;chr&gt;, Overall &lt;chr&gt;, Overall &lt;chr&gt;,\n#   Overall &lt;chr&gt;\n\n\n\n#selection of conference\nacc_stats &lt;- result[[1]]\nbe_stats &lt;- result[[6]]\nb10_stats &lt;- result[[9]]\nsec_stats &lt;- result[[23]]"
  },
  {
    "objectID": "miniproject2.html#data-cleaning",
    "href": "miniproject2.html#data-cleaning",
    "title": "Table Scraping Acquisition",
    "section": "Data Cleaning",
    "text": "Data Cleaning\n\n#ACC tibble\nacc_stats |&gt;\n  row_to_names(row_number = 1) |&gt;\n  clean_names() |&gt;\n  rename(team = x, conference_wins = w, conference_losses = l, \n         conference_pct = pct, overall_wins = w_2, \n         overall_losses = l_2, overall_pct = pct_2) |&gt;\n  select(-starts_with(\"na\"))\n\n# A tibble: 18 × 8\n   team           conference_wins conference_losses conference_pct overall_wins\n   &lt;chr&gt;          &lt;chr&gt;           &lt;chr&gt;             &lt;chr&gt;          &lt;chr&gt;       \n 1 Duke           19              1                 0.950          35          \n 2 Clemson        18              2                 0.900          27          \n 3 Louisville     18              2                 0.900          27          \n 4 SMU            13              7                 0.650          24          \n 5 Wake Forest    13              7                 0.650          21          \n 6 North Carolina 13              7                 0.650          23          \n 7 Stanford       11              9                 0.550          21          \n 8 Georgia Tech   10              10                0.500          17          \n 9 Pittsburgh     8               12                0.400          17          \n10 Florida St.    8               12                0.400          17          \n11 Virginia       8               12                0.400          15          \n12 Notre Dame     8               12                0.400          15          \n13 Virginia Tech  8               12                0.400          13          \n14 Syracuse       7               13                0.350          14          \n15 California     6               14                0.300          14          \n16 NC State       5               15                0.250          12          \n17 Boston College 4               16                0.200          12          \n18 Miami (FL)     3               17                0.150          7           \n# ℹ 3 more variables: overall_losses &lt;chr&gt;, overall_pct &lt;chr&gt;, streak &lt;chr&gt;\n\n#create a function to clean the data for multiple different conferences\nclean_tibble &lt;- function(conference){\n  conference |&gt;\n  row_to_names(row_number = 1) |&gt;\n  clean_names() |&gt;\n  rename(team = x, conference_wins = w, conference_losses = l, \n         conference_pct = pct, overall_wins = w_2, \n         overall_losses = l_2, overall_pct = pct_2) |&gt;\n  select(-starts_with(\"na\"))\n}\n\n\n#label tibble by conference\nacc_tib &lt;- clean_tibble(acc_stats)\nbe_tib &lt;- clean_tibble(be_stats)\nb10_tib &lt;- clean_tibble(b10_stats)\nsec_tib &lt;- clean_tibble(sec_stats)\n\n\n#rename conference name column\nacc_tib$conference &lt;- \"ACC\"\nbe_tib$conference &lt;- \"Big East\"\nb10_tib$conference &lt;- \"Big Ten\"\nsec_tib$conference &lt;- \"SEC\"\n\n\n\n#combine data\nncaa_bb &lt;- acc_tib |&gt;\n  bind_rows(be_tib, b10_tib, sec_tib)\n\n\nhead(ncaa_bb)\n\n# A tibble: 6 × 9\n  team           conference_wins conference_losses conference_pct overall_wins\n  &lt;chr&gt;          &lt;chr&gt;           &lt;chr&gt;             &lt;chr&gt;          &lt;chr&gt;       \n1 Duke           19              1                 0.950          35          \n2 Clemson        18              2                 0.900          27          \n3 Louisville     18              2                 0.900          27          \n4 SMU            13              7                 0.650          24          \n5 Wake Forest    13              7                 0.650          21          \n6 North Carolina 13              7                 0.650          23          \n# ℹ 4 more variables: overall_losses &lt;chr&gt;, overall_pct &lt;chr&gt;, streak &lt;chr&gt;,\n#   conference &lt;chr&gt;"
  },
  {
    "objectID": "miniproject2.html#data-analysis",
    "href": "miniproject2.html#data-analysis",
    "title": "Table Scraping Acquisition",
    "section": "Data Analysis",
    "text": "Data Analysis\n\n#Graph of Overall and Conference Percentage Evaluation\n\nncaa_bb |&gt;\n  group_by(conference) |&gt;\n  slice_max(order_by = overall_wins, n = 5) |&gt;\n  ungroup() |&gt;\n  ggplot(aes(x = conference_pct, y = overall_pct, color = conference)) +\n  geom_point(size = 3, alpha = 0.9) +\n  geom_text(aes(label = team), hjust = 0.5, vjust = -0.7, size = 3) +\n  labs(title = \"Conference vs. Overall Wins Percentage\",\n       subtitle = \"Fitered by Top 5 Conference Winning Teams\", \n       x = \"Conference Percentage\",\n       y = \"Overall Percentage\",\n       color = \"Conference\",\n       caption = \"Table Scraped from (https://www.ncaa.com/standings/basketball-men/d1)\")\n\n\n\n\n\n\n\n\nThis scatterplot graph represents the relationship between overall percentage and conference percentage of wins and loses for a given team. For our analysis, we chose the top five winning teams from the selected conferences. From this, the colors represent these selected conferences while the teams are displayed above their respective statistics. From this graph, we can see that Duke for this season has the highest overall and conference winning percentage, while the other two teams in the selected conferences that represent the rank of one for this year’s championship tournament (Florida & Auburn) are of slightly lower percentage. This also brings up an interesting point as St. John’s has a higher percentage for both conference and overall and were seeded at a number two ranking. Without the results of this championship, this would suggest a solid point to the committee for the selection of these rankings. In addition, it appears that the Big East conference season for these selected five teams are on average to play at a lower level of overall and conference performance with one outlier being St. John’s, which could also weigh in on selection rankings as well. From this analysis, it is intriguing to see the relationship between the overall percentage and the conference percentage and how it may be able to inform real decisions and could perhaps be used as a tool for the perfect bracket."
  },
  {
    "objectID": "miniproject2.html#conclusion",
    "href": "miniproject2.html#conclusion",
    "title": "Table Scraping Acquisition",
    "section": "Conclusion",
    "text": "Conclusion\nIn conclusion, this evaluation provides insights into future analysis that can and may be conducted when it comes to looking at overall and conference performance. It began with the table scraping methods that were used from the data of the NCAA’s website of the College Men’s Basketball Standings. From there, the use of cleaning the data and bringing this data into a clear and concise table to where further analysis can be conducted on it become pertinent. Through the use of plots, we further demonstrated that the relationship between overall performances and conference performances has intriguing insights when it comes to ranking selections. This analysis serves as an approach and can be used more in depth to help with the ranking selection as well as the prediction for brackets if used on a larger scale."
  },
  {
    "objectID": "miniproject2.html#sources",
    "href": "miniproject2.html#sources",
    "title": "Table Scraping Acquisition",
    "section": "Sources:",
    "text": "Sources:\nNCAA College Men’s Basketball: https://www.ncaa.com/standings/basketball-men/d1 Accessed by: Tuesday, March 25 2025\nNCAA College Men’s Basketball Championship Wins by Conference: https://www.espn.com/mens-college-basketball/story/_/id/39862064/which-ncaa-mens-conference-most-basketball-titles Accessed by: Tuesday, March 25, 2025\nLabel points(geom_text): index.html Accessed by: Wednesday, March 26, 2025"
  },
  {
    "objectID": "mini_project1_ceminsky.html",
    "href": "mini_project1_ceminsky.html",
    "title": "Interactive Chloropleth Maps",
    "section": "",
    "text": "The data used for this project comes from the Center for Disease Control (CDC) and the National Center for Health Statistics (NCHS). It can be accessed at this link.\nPreparing datasets for joining\n\n#Selecting the necessary columns for mapping\n\nstates_polygon &lt;- as_tibble(map_data(\"state\")) |&gt;\n  select(region, group, order, lat, long) \n\n#Mutating state name to be lowercase so it can be joined with states_polygon\n\ncauses_of_death_lower &lt;- causes_of_death |&gt;\n  mutate(State = str_to_lower(State))\n\nCreating Total Number of Deaths dataframe and Joins\n\n#Calculating the total number of deaths in 2017 for each state\n\ndeath_total &lt;- causes_of_death_lower |&gt;\n  rename(cause = \"Cause Name\", \n         state = State, \n         deaths = Deaths) |&gt;\n  filter(Year == \"2017\", \n         cause == \"All causes\") |&gt;\n  filter(state != \"United States\") |&gt;\n  select(deaths, state)\n\n#Joining states_polygon with death_total for total deaths per state plot\n\ndeath_total_polygon &lt;- states_polygon |&gt;\n  left_join(death_total, by = c(\"region\" = \"state\"))"
  },
  {
    "objectID": "mini_project1_ceminsky.html#introduction",
    "href": "mini_project1_ceminsky.html#introduction",
    "title": "Interactive Chloropleth Maps",
    "section": "",
    "text": "The data used for this project comes from the Center for Disease Control (CDC) and the National Center for Health Statistics (NCHS). It can be accessed at this link.\nPreparing datasets for joining\n\n#Selecting the necessary columns for mapping\n\nstates_polygon &lt;- as_tibble(map_data(\"state\")) |&gt;\n  select(region, group, order, lat, long) \n\n#Mutating state name to be lowercase so it can be joined with states_polygon\n\ncauses_of_death_lower &lt;- causes_of_death |&gt;\n  mutate(State = str_to_lower(State))\n\nCreating Total Number of Deaths dataframe and Joins\n\n#Calculating the total number of deaths in 2017 for each state\n\ndeath_total &lt;- causes_of_death_lower |&gt;\n  rename(cause = \"Cause Name\", \n         state = State, \n         deaths = Deaths) |&gt;\n  filter(Year == \"2017\", \n         cause == \"All causes\") |&gt;\n  filter(state != \"United States\") |&gt;\n  select(deaths, state)\n\n#Joining states_polygon with death_total for total deaths per state plot\n\ndeath_total_polygon &lt;- states_polygon |&gt;\n  left_join(death_total, by = c(\"region\" = \"state\"))"
  },
  {
    "objectID": "mini_project1_ceminsky.html#total-deaths-static-plot",
    "href": "mini_project1_ceminsky.html#total-deaths-static-plot",
    "title": "Interactive Chloropleth Maps",
    "section": "Total Deaths Static Plot",
    "text": "Total Deaths Static Plot\n\n#Creates a map showing the total number of deaths per state\n\ndeath_total_polygon |&gt;\n  ggplot(aes(x = long, y = lat,\n                          group = group)) + \n  geom_polygon(aes(fill = deaths), colour = \"white\", linetype = 1) +\n  scale_fill_viridis_c() +\n  labs(\n    title = \"Total Deaths per State in 2017 is related to State Population\",\n    fill = \"Number of Deaths\",\n    x = \"Longitude\",\n    y = \"Latitude\",\n    caption = \"Data Source: CDC/NCHS (https://healthdata.gov/d/nxxk-8p52)\"\n  )\n\n\n\n\n\n\n\n\nAlt text: This choropleth map shows the total number of deaths per state in 2017. The map of the United States is plotted on a grid with longitude plotted on the x-axis, ranging from -125 to -65, and latitude on the y-axis ranging from 25 to 50. States are colored on a scale, ranging from dark purple to yellow, based on their total number of deaths. Number of deaths range from 0, which is depicted by a dark purple, to 250000 deaths, which is a bright yellow color. States that have larger populations, such as California, have higher total deaths than states with smaller populations, such as North Dakota. Overall, this trend shows that states with larger populations tend to have a higher total number of deaths because as population increases, number of deaths also proportionally increases.\nManipulating data and joins\n\nsf_use_s2(FALSE)\n\n#Creates a dataframe with total number of deaths by state for join with states_sf\n\ndeath_total_upper &lt;- causes_of_death |&gt;\n  rename(cause = \"Cause Name\", \n         state = State, \n         deaths = Deaths) |&gt;\n  filter(Year == \"2017\", \n         cause == \"All causes\") |&gt;\n  filter(state != \"United States\") |&gt;\n  select(deaths, state)\n\n#Joins the states_sf dataset  with the death_total_upper dataframe to find total number of deaths by state in an interactive map\n\ndeath_total_sf &lt;- states_sf |&gt;\n  filter(!(name %in% c(\"Alaska\", \"Hawaii\", \"Puerto Rico\"))) |&gt;\n  left_join(death_total_upper, by = c(\"name\" = \"state\"))"
  },
  {
    "objectID": "mini_project1_ceminsky.html#interactive-map-of-total-deaths",
    "href": "mini_project1_ceminsky.html#interactive-map-of-total-deaths",
    "title": "Interactive Chloropleth Maps",
    "section": "Interactive map of Total Deaths",
    "text": "Interactive map of Total Deaths\n\n#Creates labels that can be used in an interactive plot\n\ndeath_total_sf &lt;- death_total_sf |&gt;\n  mutate(labels = str_c(name, \": \", deaths, \" deaths\"))\n        \nlabels_total &lt;- lapply(death_total_sf$labels, HTML)\n\n#Creates bins and a color palette to be used in the interactive map\n\nbins &lt;- c(0, 10000, 20000, 50000, 100000, 150000, 200000, 250000, Inf)\npal &lt;- colorBin(\"viridis\", domain = death_total_sf$deaths, bins = bins)\n\n#Creates the interactive map of the total number of deaths by state\n\nleaflet(death_total_sf) |&gt;\n  setView(-96, 37.8, 4) |&gt;\n  addTiles() |&gt;\n  addPolygons(\n    fillColor = ~pal(deaths),\n    weight = 2,\n    opacity = 1,\n    color = \"white\",\n    dashArray = \"1\",\n    fillOpacity = 0.7,\n    highlightOptions = highlightOptions(\n      weight = 5,\n      color = \"#666\",\n      dashArray = \"\",\n      fillOpacity = 0.7,\n      bringToFront = TRUE),\n    label = labels_total,\n    labelOptions = labelOptions(\n      style = list(\"font-weight\" = \"normal\", padding = \"3px 8px\"),\n      textsize = \"15px\",\n      direction = \"auto\")) |&gt;\n  addLegend(pal = pal, values = ~deaths, opacity = 0.7, title = NULL,\n    position = \"bottomright\")\n\n\n\n\n\nCauses of Death dataframe and joins\n\n#Creates a dataframe finding the most common cause of death by state in 2017\n\ndeath_order_lower &lt;- causes_of_death_lower |&gt;\n  rename(cause = \"Cause Name\", \n         state = State,\n         death = Deaths) |&gt;\n  filter(Year == 2017, \n         cause != \"All causes\", \n         state != \"united states\") |&gt;\n  group_by(state, cause) |&gt;\n  summarize(total_deaths = sum(death, na.rm = TRUE)) |&gt;\n  group_by(state) |&gt;\n  slice_max(total_deaths, n = 1) |&gt;\n  ungroup()\n\n#Joins the states_polygon mapping dataset with the death_order_lower dataframe created about leading cause of death\n\ndeath_order_polygon &lt;- states_polygon |&gt;\n  left_join(death_order_lower, by = c(\"region\" = \"state\"))"
  },
  {
    "objectID": "mini_project1_ceminsky.html#static-plot-of-leading-cause-of-death-by-state",
    "href": "mini_project1_ceminsky.html#static-plot-of-leading-cause-of-death-by-state",
    "title": "Interactive Chloropleth Maps",
    "section": "Static plot of Leading cause of death by state",
    "text": "Static plot of Leading cause of death by state\n\n#Creates static map of the leading cause of death in 2017 by state\n\ndeath_order_polygon |&gt;\n  ggplot(aes(x = long, y = lat,\n                          group = group)) + \n  geom_polygon(aes(fill = cause), colour = \"black\", linetype = 1) +\n  scale_fill_brewer() +\n    labs(\n      title = \"The Leading Cause of Death by State in 2017 is \\n Predominantly Heart Disease\",\n      x = \"Longitude\",\n      y = \"Latitude\",\n      fill = \"Cause\",\n      caption = \"Data Source: CDC/NCHS (https://healthdata.gov/d/nxxk-8p52)\"\n      )\n\n\n\n\n\n\n\n\nThis choropleth map shows the most common cause of death in each state for 2017. The most common cause of death across the US is heart disease, with a majority of states reporting heart disease as its leading cause of death. The second most common leading cause of death is cancer, with about 11 states reporting cancer as causing the highest number of deaths. These are the only two causes of death that are the leading causes in a state.\nCreating dataframe used in interactive plot for Leading Cause of Death\n\n#Creates dataframe with most common cause of death by state for join with states_sf\n\ndeath_order &lt;- causes_of_death |&gt;\n  rename(cause = \"Cause Name\", \n         state = State,\n         death = Deaths) |&gt;\n  filter(Year == 2017, \n         cause != \"All causes\", \n         state != \"United States\") |&gt;\n  group_by(state, cause) |&gt;\n  summarize(total_deaths = sum(death, na.rm = TRUE)) |&gt;\n  group_by(state) |&gt;\n  slice_max(total_deaths, n = 1) |&gt;\n  ungroup()\n\n#Joins states_sf with the death_order dataframe created\n\ndeath_order_sf &lt;- states_sf |&gt;\n  filter(!(name %in% c(\"Alaska\", \"Hawaii\", \"Puerto Rico\"))) |&gt;\n  left_join(death_order, by = c(\"name\" = \"state\"))"
  },
  {
    "objectID": "mini_project1_ceminsky.html#interactive-map-of-leading-cause-of-death-by-state",
    "href": "mini_project1_ceminsky.html#interactive-map-of-leading-cause-of-death-by-state",
    "title": "Interactive Chloropleth Maps",
    "section": "Interactive Map of Leading Cause of Death by State",
    "text": "Interactive Map of Leading Cause of Death by State\n\n#Creates and formats labels that will be used in the interactive map\n\ndeath_order_sf &lt;- death_order_sf |&gt;\n  mutate(labels_order = str_c(name, \": \", cause, \" is the leading cause of death\"))\n\nlabels_order &lt;- lapply(death_order_sf$labels_order, HTML)\n\n#Creates color palette used in the interactive map\n\npal_order &lt;- colorFactor(palette = \"Greens\", domain = death_order_sf$cause)\n\n#Creates interactive map of the leading cause of death by state in 2017\n\nleaflet(death_order_sf) |&gt;\n  setView(-96, 37.8, 4) |&gt;\n  addTiles() |&gt;\n  addPolygons(\n    fillColor = ~pal_order(cause),\n    weight = 2,\n    opacity = 1,\n    color = \"black\",\n    dashArray = \"1\",\n    fillOpacity = 0.8,\n    highlightOptions = highlightOptions(\n      weight = 5,\n      color = \"#666\",\n      dashArray = \"\",\n      fillOpacity = 0.7,\n      bringToFront = TRUE),\n    label = labels_order,\n    labelOptions = labelOptions(\n      style = list(\"font-weight\" = \"normal\", padding = \"3px 8px\"),\n      textsize = \"15px\",\n      direction = \"auto\")) |&gt;\n  addLegend(pal = pal_order, values = ~cause, opacity = 0.7, title = NULL,\n    position = \"bottomright\")"
  },
  {
    "objectID": "research.html",
    "href": "research.html",
    "title": "Research",
    "section": "",
    "text": "I am involved in research at St. Olaf with Dr. Piercarlo Valdesolo, a psychology professor specializing in emotions research. Our current project examines the feelings of gratitude that immigrants have and feel they ought to have toward their country of resettlement.\n\n\n\nWe prepared this research poster to be presented at MPA in Chicago this spring."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Olivia Ceminsky",
    "section": "",
    "text": "My name is Olivia Ceminsky, and I am a junior at St. Olaf College studying Psychology with a concentration in International Relations. I am taking Data Science 2 this spring."
  }
]